---
layout: post
author: Larry Chen
tags: [cscc]
---

# [AI and Emerging Technologies]

## Question 1: What emerging technology did you choose? How is AI being used to support this technology?

AI-powered recruitment tools are transforming the hiring process by **automating applicant screening, ranking candidates, and conducting initial interviews**. These tools leverage **machine learning algorithms** to process large applicant pools efficiently, reducing human workload and time-to-hire.

### **Examples of AI Recruitment Platforms:**
- **HireVue** – Uses AI-driven video interviews and predictive analytics to assess candidates ([HireVue](https://www.hirevue.com)).
- **Harver (formerly Pymetrics)** – Employs neuroscience-based games and AI to match candidates based on cognitive and emotional traits. Harver acquired Pymetrics in 2022 ([Harver](https://www.harver.com/)).

However, AI hiring models trained on historical data have been found to **reinforce gender biases**, often favoring male applicants in male-dominated industries. 

For example, **Amazon’s AI hiring tool was discontinued** after researchers found that the system **downgraded resumes containing the word "women’s"** (e.g., *“women’s chess club”*). The AI learned this bias from patterns in past hiring decisions, where male candidates were historically favored in technical roles ([Reuters, 2018](https://www.reuters.com/article/world/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK0AG/)).

This highlights the **need for bias mitigation strategies** in AI-driven recruitment, including:
- Implementing **bias audits** to detect and correct discriminatory patterns.
- Training models on **diverse and inclusive datasets**.
- Ensuring **human oversight** in the decision-making process.

---

## Question 2: Are there any concerns with using AI for this application?

### **Key Concerns in AI-Powered Hiring**
1. **Algorithmic Bias & Discrimination**
   - If AI models are trained on biased historical hiring data, they can **amplify gender, racial, and socioeconomic discrimination**.
   - **A 2024 study by the University of Washington** found that large language models favored white male-associated names **85% of the time** during resume evaluations, highlighting significant **gender and racial biases** in AI-assisted hiring ([University of Washington, 2024](https://www.washington.edu/news/2024/10/31/ai-bias-resume-screening-race-gender/)).

2. **Lack of Transparency ("Black Box AI")**
   - Many AI models function as **black boxes**, meaning **their decision-making process is not easily explainable**.
   - This raises ethical concerns about **fairness, accountability, and legal compliance**.

### **Solutions for Ethical AI Hiring**
To address these concerns, organizations should:
- **Adopt Explainable AI (XAI) models** to improve transparency in hiring decisions.
- **Conduct fairness testing & bias audits** to prevent discrimination.
- **Ensure compliance** with anti-discrimination laws such as the **EEOC (Equal Employment Opportunity Commission) guidelines** ([EEOC](https://www.eeoc.gov/)).
- **Involve diverse stakeholders** in AI model development to create fairer and more inclusive hiring systems.

AI has the potential to **revolutionize recruitment**, but **ethical considerations must remain a priority** to ensure fair and unbiased hiring processes.
